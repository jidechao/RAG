{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_BASE = os.environ.get(\"OPENAI_API_BASE\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "LANGCHAIN_TRACING_V2 = os.environ.get(\"LANGCHAIN_TRACING_V2\")\n",
    "LANGCHAIN_ENDPOINT = 'https://api.smith.langchain.com'\n",
    "LANGCHAIN_API_KEY = os.environ.get(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Apps\\miniconda3\\envs\\rag\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "llm = ChatOpenAI(model=\"qwen-max\", temperature=0)\n",
    "\n",
    "model_name = \"C:\\\\Home\\\\Documents\\\\Projects\\\\models\\\\BAAI\\\\bge-large-en-v1.5\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "embedding_model = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "vectorstore = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"rag_from_scratch\",\n",
    "    embedding=embedding_model,\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate HyDE document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = \"\"\"Please write a scientific paper passage to answer the question\n",
    "Question: {question}\n",
    "Passage:\"\"\"\n",
    "\n",
    "prompt_hyde = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "generate_docs_for_retrieval = (prompt_hyde | llm | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Task Decomposition for Large Language Model (LLM) Agents: A Framework for Enhanced Problem Solving**\n",
      "\n",
      "In the realm of artificial intelligence, large language models (LLMs) have emerged as powerful tools capable of handling a wide array of tasks, from natural language understanding and generation to complex problem-solving. However, the effectiveness of LLMs in solving intricate and multifaceted problems can be significantly enhanced through the process of task decomposition. Task decomposition refers to the systematic breakdown of a complex task into smaller, more manageable sub-tasks, each of which can be addressed independently or in a coordinated manner. This approach not only simplifies the problem-solving process but also allows LLMs to leverage their strengths more effectively.\n",
      "\n",
      "The primary goal of task decomposition is to transform a high-level, often ambiguous, task into a series of well-defined, discrete steps. This is particularly important for LLMs, as they are typically trained on vast datasets that encompass a broad range of topics and contexts. By decomposing a task, an LLM can focus on specific aspects of the problem, thereby reducing the cognitive load and improving the accuracy and efficiency of the solution. For example, a task such as \"plan a week-long vacation to Paris\" can be decomposed into sub-tasks such as \"research popular tourist attractions,\" \"book accommodation,\" \"arrange transportation,\" and \"create a daily itinerary.\"\n",
      "\n",
      "The process of task decomposition can be approached in several ways, depending on the nature of the task and the desired outcome. One common method is hierarchical decomposition, where the main task is broken down into a hierarchy of sub-tasks, with each level of the hierarchy representing a different level of detail. Another method is parallel decomposition, where the main task is divided into multiple sub-tasks that can be executed concurrently, potentially leading to faster problem resolution. Additionally, sequential decomposition involves breaking down the task into a sequence of sub-tasks that must be completed in a specific order.\n",
      "\n",
      "To implement task decomposition effectively, it is essential to define clear criteria for the sub-tasks, including their objectives, constraints, and dependencies. This ensures that each sub-task is well-defined and can be executed independently, while still contributing to the overall solution. Furthermore, the output of each sub-task should be structured in a way that facilitates integration and coordination with other sub-tasks, ultimately leading to a coherent and comprehensive solution.\n",
      "\n",
      "In summary, task decomposition is a crucial technique for enhancing the problem-solving capabilities of LLM agents. By breaking down complex tasks into smaller, more manageable sub-tasks, LLMs can leverage their extensive knowledge and computational power more effectively, leading to more accurate, efficient, and robust solutions. As LLMs continue to evolve, the development of advanced task decomposition methods will play a vital role in unlocking their full potential across a wide range of applications.\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "\n",
    "hypothetical_doc = generate_docs_for_retrieval.invoke({\"question\": question})\n",
    "\n",
    "print(hypothetical_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', '_id': 'ca53f36c-9331-4f43-bc8f-5b5e8f788d57', '_collection_name': 'rag_from_scratch'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain = generate_docs_for_retrieval | retriever \n",
    "\n",
    "retireved_docs = retrieval_chain.invoke({\"question\": question})\n",
    "\n",
    "retireved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition for LLM (Large Language Model) agents is the process of breaking down a complex task into smaller, more manageable subtasks. This technique helps the model to handle and solve intricate problems by addressing them step-by-step. The document mentions two key methods for task decomposition:\n",
      "\n",
      "1. **Chain of Thought (CoT)**: This method, introduced by Wei et al. in 2022, involves instructing the model to think through the problem step by step. By doing so, the model can utilize more computational resources at test time to decompose difficult tasks into simpler, smaller steps. This not only makes the task easier to manage but also provides insight into the model's reasoning process.\n",
      "\n",
      "2. **Tree of Thoughts**: Proposed by Yao et al. in 2023, this approach extends the concept of CoT by exploring multiple reasoning possibilities at each step. It first breaks down the problem into multiple thought steps and then generates multiple thoughts per step, forming a tree-like structure. The search through these thoughts can be conducted using breadth-first search (BFS) or depth-first search (DFS), with each state being evaluated either by a classifier (through a prompt) or by majority vote.\n",
      "\n",
      "Task decomposition can be achieved in several ways:\n",
      "- Using simple prompts, such as \"Steps for XYZ. 1.\" or \"What are the subgoals for achieving XYZ?\"\n",
      "- Employing task-specific instructions, like \"Write a story outline\" for writing a novel.\n",
      "- Incorporating human inputs to guide the decomposition process.\n",
      "\n",
      "Overall, task decomposition enhances the ability of LLM agents to tackle complex tasks by systematically breaking them down into simpler components.\n"
     ]
    }
   ],
   "source": [
    "# RAG\n",
    "\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = final_rag_chain.invoke({\"context\": retireved_docs, \"question\": question})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
