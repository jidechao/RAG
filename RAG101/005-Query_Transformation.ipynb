{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查询重写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_write_llm = ChatOpenAI(model=\"qwen-max\", temperature=0, max_tokens=4000)\n",
    "\n",
    "# Create a prompt template for query rewriting\n",
    "query_rewrite_template = \"\"\"You are an AI assistant tasked with reformulating user queries to improve retrieval in a RAG system. \n",
    "Given the original query, rewrite it to be more specific, detailed, and likely to retrieve relevant information.\n",
    "\n",
    "Original query: {original_query}\n",
    "\n",
    "Rewritten query:\"\"\"\n",
    "\n",
    "query_rewrite_prompt = PromptTemplate(\n",
    "    input_variables=[\"original_query\"], template=query_rewrite_template\n",
    ")\n",
    "\n",
    "# Create an LLMChain for query rewriting\n",
    "query_rewriter = query_rewrite_prompt | re_write_llm\n",
    "\n",
    "\n",
    "def rewrite_query(original_query):\n",
    "    \"\"\"\n",
    "    Rewrite the original query to improve retrieval.\n",
    "\n",
    "    Args:\n",
    "    original_query (str): The original user query\n",
    "\n",
    "    Returns:\n",
    "    str: The rewritten query\n",
    "    \"\"\"\n",
    "    response = query_rewriter.invoke(original_query)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始查询:  气候变化对环境的影响是什么？\n",
      "\n",
      "查询重写:  气候变化对环境的具体影响有哪些，包括但不限于极端天气事件、海平面上升以及生态系统的变化？\n"
     ]
    }
   ],
   "source": [
    "# example query over the understanding climate change dataset\n",
    "original_query = \"气候变化对环境的影响是什么？\"\n",
    "rewritten_query = rewrite_query(original_query)\n",
    "print(\"原始查询: \", original_query)\n",
    "print(\"\\n查询重写: \", rewritten_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回溯提示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_back_llm = ChatOpenAI(model=\"qwen-max\", temperature=0, max_tokens=4000)\n",
    "\n",
    "\n",
    "# Create a prompt template for step-back prompting\n",
    "step_back_template = \"\"\"You are an AI assistant tasked with generating broader, more general queries to improve context retrieval in a RAG system.\n",
    "Given the original query, generate a step-back query that is more general and can help retrieve relevant background information.\n",
    "\n",
    "Original query: {original_query}\n",
    "\n",
    "Step-back query:\"\"\"\n",
    "\n",
    "step_back_prompt = PromptTemplate(\n",
    "    input_variables=[\"original_query\"], template=step_back_template\n",
    ")\n",
    "\n",
    "# Create an LLMChain for step-back prompting\n",
    "step_back_chain = step_back_prompt | step_back_llm\n",
    "\n",
    "\n",
    "def generate_step_back_query(original_query):\n",
    "    \"\"\"\n",
    "    Generate a step-back query to retrieve broader context.\n",
    "\n",
    "    Args:\n",
    "    original_query (str): The original user query\n",
    "\n",
    "    Returns:\n",
    "    str: The step-back query\n",
    "    \"\"\"\n",
    "    response = step_back_chain.invoke(original_query)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始查询:  气候变化对环境的影响是什么？\n",
      "\n",
      "回溯提示:  气候变化对地球有哪些主要影响？\n"
     ]
    }
   ],
   "source": [
    "original_query = \"气候变化对环境的影响是什么？\"\n",
    "rewritten_query = generate_step_back_query(original_query)\n",
    "print(\"原始查询: \", original_query)\n",
    "print(\"\\n回溯提示: \", rewritten_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 子查询分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_query_llm = ChatOpenAI(model=\"qwen-max\", temperature=0, max_tokens=4000)\n",
    "\n",
    "# Create a prompt template for sub-query decomposition\n",
    "subquery_decomposition_template = \"\"\"You are an AI assistant tasked with breaking down complex queries into simpler sub-queries for a RAG system.\n",
    "Given the original query, decompose it into 2-4 simpler sub-queries that, when answered together, would provide a comprehensive response to the original query.\n",
    "\n",
    "Original query: {original_query}\n",
    "\n",
    "example: What are the impacts of climate change on the environment?\n",
    "\n",
    "Sub-queries:\n",
    "1. What are the impacts of climate change on biodiversity?\n",
    "2. How does climate change affect the oceans?\n",
    "3. What are the effects of climate change on agriculture?\n",
    "4. What are the impacts of climate change on human health?\"\"\"\n",
    "\n",
    "\n",
    "subquery_decomposition_prompt = PromptTemplate(\n",
    "    input_variables=[\"original_query\"], template=subquery_decomposition_template\n",
    ")\n",
    "\n",
    "# Create an LLMChain for sub-query decomposition\n",
    "subquery_decomposer_chain = subquery_decomposition_prompt | sub_query_llm\n",
    "\n",
    "\n",
    "def decompose_query(original_query: str):\n",
    "    \"\"\"\n",
    "    Decompose the original query into simpler sub-queries.\n",
    "\n",
    "    Args:\n",
    "    original_query (str): The original complex query\n",
    "\n",
    "    Returns:\n",
    "    List[str]: A list of simpler sub-queries\n",
    "    \"\"\"\n",
    "    response = subquery_decomposer_chain.invoke(original_query).content\n",
    "    sub_queries = [\n",
    "        q.strip()\n",
    "        for q in response.split(\"\\n\")\n",
    "        if q.strip() and not q.strip().startswith(\"Sub-queries:\")\n",
    "    ]\n",
    "    return sub_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "子查询:\n",
      "Original query: 气候变化对环境的影响是什么？\n",
      "1. 气候变化如何影响生物多样性？\n",
      "2. 气候变化对海洋生态系统有什么影响？\n",
      "3. 气候变化对农业生产有何影响？\n",
      "4. 气候变化对自然栖息地和森林有哪些影响？\n"
     ]
    }
   ],
   "source": [
    "# example query over the understanding climate change dataset\n",
    "original_query = \"气候变化对环境的影响是什么？\"\n",
    "sub_queries = decompose_query(original_query)\n",
    "print(\"\\n子查询:\")\n",
    "for i, sub_query in enumerate(sub_queries, 1):\n",
    "    print(sub_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
